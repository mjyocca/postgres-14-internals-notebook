
## 1.1 Data Organization
* Databases
* System Catalog
* Schemas
* Tablespaces
* Relations
* Files and Forks
* Pages
* TOAST

## Tablespaces
Physical Data Layout - a virtual directory in a file system

## Files and Forks
"_All information associated with a relation is stored in several forks, each containing data of a particular type_"

## Pages
* Logical blocks that files are split into to reduce I/O contention.
* Smallest amount of data that can be read or written in Postgres.
* Each page size is usually 8kb to 32kb.

## TOAST
The Oversized Attribute Storage Technique

Used to store long attributes, one for each potentially long attribute.

## 1.2 Processes and Memory
* `Postmaster`: Initial process when the postgres server starts.
  - Responsible for spawing/restarting other processes. (Does not use threads)
* Other background processes:
  - startup
  - autovacuum
  - wal writer
  - checkpointer
  - writer
  - stats collector
  - wal receiver

## 1.3 Clients and the Client-Server Protocol
* Postmaster listens for incoming connections; spawns a new separate backend process for each; then creates a session.
* Problem: Connections/Processes require ram, the more connections, the more ram required.
* Solution: Connection Pooling.
* Have to rely on external connection pooling (Does not come for free!)
  - Example(s):
    * AWS RDS Proxy Service
    * PgBouncer

## 2.1 Consistency

Relational Datbases key feature is "**Data correctness**", but only to a certain point.

### Database vs Application Responsiblity

1. **Ensuring Data Consistency**: Relational databases can enforce data integrity through constraints like keys or rules, which help maintain data correctness. `NOT NULL` or `UNIQUE`
2. **Limitations of Database-Level Constraints**: Some constraints are too complex to be defined at the database level, especially when they involve multiple tables.
3. **Application's Role in Data Consistency**: While the database can ensure integrity, it cannot inherently understand the broader concept of consistency as required by specific applications.
4. **Responsibility of the Application**: The application must define and enforce data consistency criteria, as the database system cannot detect consistency breaches if they do not violate integrity constraints.
5. **Trust in Application Design**: There is an underlying assumption that the application is correctly designed and free of errors to maintain data consistency.

**Recap**: Leveraging Database-Level constraints does not cover the entirety of data consistency. Must leverage carefuul enforement and design at the application level.

## 2.2 Isolation Levels and Anomalies in SQL Standard

> NOTE: Not specific to PostgreSQL; just some backstory context!

### Types Isolation Levels Applicable for SQL Standard
* Read Uncommitted
* Read Committed
* Repeatable Read
* Serializable

### Anomalies
* **Lost Update**:
  - Impact ***none*** of the isolation levels
  - Forbidden by the SQL standard
  - Example: "_2 Transactions read and write to the same table row concurrently. The second transation writes without taking into account any changes made by the first transaction._"
* **Dirty Reads**:
  - Example: "_A transaction reads uncommitted changes made by another transaction._"
  - Allowed Isolation Level: `Read Uncommitted`
* **Non-Repeatable Reads**:
  - Example: "_A transaction reads one and the same **row** twice, whereas another transaction updates (or deletes) this row between reads and commits the changes. As a result the first transation gets different results._"
  - Allowed Isolation Levels: [`Read Uncommitted`, `Read Committed`]
* **Phantom Reads**:
  - Examples: "_One and the same transaction executes two identical queries returning a set of rows that satisfy a particular condition, while another transaction adds some other rows satisfying this condition and COMMITS the  changes in the time interval between queries. The first transaction gets two different sets of rows._"
  - Allowed Isolation Levels: [`Read Uncommitted`, `Read Committed`, `Repeatable Read`]

### Isolation Levels correlation to Anomalies

|   Isolation Level| Lost Update | Dirty Read | Non-repeatable Read | Phantom Read | Other  Anomalies |
|------------------|-------------|------------|---------------------|--------------|------------------|
| Read Uncommitted | -           | yes        | yes                 | yes          | yes              |
| Read Committed   | -           | -          | yes                 | yes          | yes              |
| Repeatable Read  | -           | -          | -                   | yes          | yes              |
| Serializable     | -           | -          | -                   | -            | -                |


The higher the isolation level; the greater the amount of locks required.

> Serializable can still experience phantom reads to occur when locking rows that do not yet exist.

## 2.3 Isolation Levels in PostgreSQL

### Snapshot Protocol
* Lock-based protocols replaced by **Snapshot Isolation (SI)** protocol.
* Snapshot: data as it appeared at a particular point in time, including all the current changes committed before the snapshot was taken.
* Benefits of Snapshots:
  - Minimizes the number of required locks.
  - Rows will be locked **only** by concurrent update attempts.
  - Writes never lock reads
  - Reads never lock anything.

### MultiVersion Concurrency Control (MVCC)
* Flavor of the SI (Snapshot Isolation) Protocol
* Postgres is stricter!! than the SQL Standard - **Dirty Reads are forbidden**

### PostgreSQL Isolation Levels and Anomalies (Compared to the Standard)

| Isolation Level | Lost Update | Dirty Read | Non-repeatable Read | Phantom Read | Other  Anomalies |
|-----------------|-------------|------------|---------------------|--------------|------------------|
| Read Committed  | yes         | -          | yes                 | yes          | yes              |
| Repeatable Read | -           | -          | -                   | -            | yes              |
| Serializable    | -           | -          | -                   | -            | -                |

- Read Committed does not allow the Dirty Read anomaly, but allows **Lost Update**
- Read Uncommitted level Isolation level is treated as Read Committed. (Ignored/Does not exist)
- Repeatable Reads level DO NOT allow anomalies:
  * Non-repeatable reads
  * Phantom Reads


### Read Committed

#### NO DIRTY READS
Cannot see any uncommitted data!

#### Non-repeatable reads
Once the data is committed; Other transaction(s) at the **Read Committed** Isolation Level, receives the updated version of the data.

_A practical insight: in a transaction, you must not take any decisions based on the
data read by the previous operator, as everything can change in between. Here is
an example whose variations appear in the application code so often that it can be
considered a classic anti-pattern_

Recommendations:
* Replace procedural code with declarative code
* Use a single SQL Operator
* Apply Explicit Locks. (Last Resort)
  - Example: `SELECT FOR UPDATE`

#### Read Skew Anomaly
* Not regulated by SQL Standard
* Happens between SQL Operators
* Example: Occurs when one transaction reads the same row multiple times, or the data in the row differs between reads.
* Recommendation: Use Single Operator.

Instead of:
**Transaction 2**
```sql
BEGIN;
-- Instead of --
SELECT amount FROM accounts WHERE id = 2;
SELECT amount FROM accounts WHERE id = 3;
-- Use Single Operator --
SELECT sum(amount) FROM accounts WHERE client = 'bob';
```

##### Read Skew Gotchas
* Long Running Queries see all the data in the state that corresponds to the beginning of its execution. Transactions with long running queries don't experience read skew directly.
* Volatile Functions Do Impact Read Skew
* Update Operators can experience read skew if subquery or condition includes data that meets criteria that is being operated on by another transaction with a lock on the row.

#### Lost Updates
Previous examples:
```sql
UPDATE accounts SET amount = amount + 100 WHERE id = 1
```

Outside the database:
```sql
UPDATE accounts SET amount = 800.00 + 100 WHERE id = 1
```

If two SQL Operators reads and registers outside the database (for example a balance), the system does not know that the registerd assigned value is related to a current column, can cause a lost update anomaly.

### Repeatable Read
* Use: `BEGIN ISOLATION LEVEL REPEATABLE READ;`
* No non-repeatable and phantom reads.
* Guarantees repeatable reading.
* Prevents all anomalies described in the SQL Standard (But not all!)
* Even though a separate transaction 1 commits its changes; if the 2nd transaction with Isolation `REPEATABLE READ;`, re-executes the query, it shall remain the same!

#### Serialization failures (instead of lost updates)
* If a transaction with `REPEATABLE READ` attempts to update a row that is locked, the transaction can only be aborted with a serialization failure.

#### Repeatable Read Allowed Anomalies
* **Write Skew**: _Two separate transactions make writes to two separate records relating to the same account. Example consistency rule dictates an individual record can have a negative value but cannot be negative across accounts._
* **Read-only transaction anomaly**: _Three separate transactions, two make writes and one is read-only. The first transaction is started prior to the second where the second transaction is committed but not the first. The third transaction starts and is read-only but since the second was committed and not the first, any state seen by the third transaction will be inconsistent. Since it sees trx 2's work and not 1's._

### Serializable
* Virtually built on top of snapshot isolation.
* Anomalies that occur at Read Committed and Repeatable Read do NOT occur.
* Anomalies such as read-only transaction will lead to serialization errors.

#### Deferring a read-only transaction.
* Use: `BEGIN ISOLATION LEVEL SERIALIZABLE;`
* Deferred until it's execution can become safe.
* Only case when a `SELECT` statement can be blocked by row updates.

#### Serializable Considerations
* Must be ready to retry transactions that have ended with a serialization failure.
* Decrease the impact by explicitly using `READ ONLY` clause when declaring read-only transactions.
* False positive failures based on luck:
  - Precense of Indexes
  - Amt of Ram available
* Limitations:
  - Cannot use Serialization Level for **Read Replicas**

## 2.4  Which Isolation Level to Use?

#### Read Committed
* Default, most commonly used.
* Aborts transactions in case of failure.
* Allows many of the anomalies, requiring applications to handle and prevent data inconsistencies (Difficult to test).

#### Repeatable Read
* Reduces inconsistency problems seen with read committed, but not all.
* Requires to handle anomolies by modifying applications to manage serialization failures.

#### Serializable
* Complete Data Consistency
* Applications need to be retry-ready for aborted transactions due to serialization failures.


## 3.1 Page Structure
* page header
* an array of item pointers
* free space
* items (row versions)
* special space

### Page Header
* Located in the lowest addresses and contains a **fixed** size.
* Stores info about the page:
  - Checksum
  - Size of all parts of the page

### Special Space
* Located at opposite end of the page (compared to the page header).
* Usage and content depends entirely on index type.

### Tuples
* See "Tuple", think Row. (Term from PostgreSQL's academic past)
* Actual data stored in the database; located prior to **special space**.
* MVCC - several versions of one and the same row.
* Indexes do NOT use MVCC mechanism;
  - Indexes reference all the available row versions.

### Item Pointers
* Array of pointers to **tuples** (Table of Contents)
* Located after the header.
* TID (six-byte Tuple Identifiers) consists of:
  - Page Number
  - Reference to Row Version located in the page
- Tuples could be identified by their offset from the start of a page.
- Moving tuples would break references, causing fragmentation and issues.
- PostgreSQL avoids this with indirect addressing:
  - Tuple identifier refers to a pointer number.
  - Pointer specifies the tuple's current offset.
- If the tuple moves, only the pointer is updated, not the identifier.

### Free Space
Free Space left between pointers and tuples.

## 3.2 Row Version Layout
* `xmin`,`xmax`: Transaction ID's used to differenciate between row versions (Tuples)
* `infomask`: Provides a set of information bits that define version properties.
* `ctid`: Pointer to next updated version of the same row.
* `null bitmap`: Array of bits marking columns that are NULL-able.

### Interesting Optimization - Discussion Point
Start tables with fixed-length columns that cannot contain NULL values.

## 3.3 Operations on Tuples
- `Xmin` & `Xmax` define "Validity time" for each **Tuple** version.
- Row creation, xmin value is set to the transaction ID of the INSERT command: { xmin: `txid`, xmax: `null` }
- Row deletion, xmax value of its current version set to the transaction ID of the DELETE command: { xmin: `..`, xmax: `txid` }
- Row updated (more expensive), creates a new tuple and marks previous version with xmax transaction ID along with a new Tuple version with xmin. In this case previous tuple version xmax == new tuple version xmin.

### Insert
* Check current transaction ID with: `SELECT pg_current_xact_id();`
* Variations of Transaction ID: [ xact, xact ID, TXID, XID ]
* Hidden page columns (shown by book how to query them)
  - `xmin_committed` & `xmin_aborted` determines whether xmin transaction is committed or aborted.
  - `xmax_committed` & `xmax_aborted` gives similar information about xmax transaction state.

### Commit
* Transactions are registered as "committed" via CLOG (commit log) structure.
* Stored to disc in the pgdata/pg_xact directory.
* Once transaction is marked as committed, stored in CLOG. Other transactions can check whether a certain xmin transaction has finished or not.

### Delete
* Tuple's `Xmax` column is set to the transaction ID that performs the deletion.
* `xmax_aborted` is unset.

### Abort
* Similar to mechanism to commit.
* Transaction that is aborted is set in CLOG.
* ROLLBACK is the command, but no data is rolled back. Instead:
  - All changes made by the aborted transaction remains in place.
* Transaction status is checked, and tuples receives `xmax_aborted` hint.
* Ignored by rest of the databased for reads and writes.

### Update
* Delete and Insert in place.
* New tuple is inserted containing `Xmin` with current Transaction ID.
* `Xmax` of previous TUPLE version contains current Transaction ID.
* `xmax_aborted` is unset (Until/IF transaction is aborted)

## 3.4 Indexes
* Indexes do not use row versioning
* Index row headers do not contain xmin, xmax
* Index entries point to all versions of the corresponding table row.

## 3.5 TOAST
* A regular table with it's own separate versioning.
* Independent on row versions of the main table.
* When a tuple is created/updated in the main table with no change in long values stored in TOAST, new tuple will reference existing toast value.
* When long value is updated, PG will create a new tuple in the main table and new "toasts".

## 3.6 Virtual Transactions
* Read-Only Transactions that have no affect on row visibility.
* Given a "virtual XID" at first, exists only in RAM and can be re-used (no synchronization required)
* Virtual XID: process ID + Seq Number.
* Once Transaction modify's data, it receives an actual unique ID.
